# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZpEqqGFOE1JvffJ07fFysMzu_PI9rYdm
"""

# src/model.ipynb

import torch
from transformers import AutoModel, AutoTokenizer

class MultiTaskSentenceTransformer(torch.nn.Module):
    def __init__(self, model_name="bert-base-uncased", num_classes=3, num_ner_labels=5):
        super(MultiTaskSentenceTransformer, self).__init__()
        self.transformer = AutoModel.from_pretrained(model_name)
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)

        # Task-specific heads
        self.classification_head = torch.nn.Linear(self.transformer.config.hidden_size, num_classes)
        self.ner_head = torch.nn.Linear(self.transformer.config.hidden_size, num_ner_labels)

    def forward(self, sentences, task="classification"):
        inputs = self.tokenizer(sentences, return_tensors="pt", padding=True, truncation=True)
        outputs = self.transformer(**inputs)

        if task == "classification":
            pooled_output = outputs.last_hidden_state.mean(dim=1)
            return self.classification_head(pooled_output)

        elif task == "ner":
            token_embeddings = outputs.last_hidden_state
            return self.ner_head(token_embeddings)

import torch

# Initialize the multi-task model
model = MultiTaskSentenceTransformer(model_name="bert-base-uncased", num_classes=3, num_ner_labels=5)

# Sample sentences for testing
sentences = ["The AI model is working well.", "OpenAI creates amazing technology."]

# Example for Task A: Sentence Classification
classification_outputs = model(sentences, task="classification")
print("Classification Outputs:")
print(classification_outputs)

# Example for Task B: Named Entity Recognition (NER)
ner_outputs = model(sentences, task="ner")
print("\nNER Outputs:")
print(ner_outputs)

